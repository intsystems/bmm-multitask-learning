{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport data\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirill/.cache/pypoetry/virtualenvs/bmm-multitask-learning-_LQwnQjl-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from pipe import select\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import optim\n",
    "\n",
    "import pyro\n",
    "import pyro.nn as pnn\n",
    "import pyro.distributions as pdistr\n",
    "import pyro.infer\n",
    "from pyro.infer import Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoNormal\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "from torchmetrics.classification import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import build_linked_datasets, build_solo_dataset\n",
    "\n",
    "NUM_MODELS = 3\n",
    "\n",
    "train_datasets, test_datasets = zip(*\n",
    "    (*build_linked_datasets(config.size, config.dim), build_solo_dataset(config.size, config.dim)) |\n",
    "    select(lambda dataset: random_split(dataset, [1 - config.test_ratio, config.test_ratio]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoloModel(pnn.PyroModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int = 2,\n",
    "        num_data_samples: Optional[int] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_data_samples = num_data_samples\n",
    "\n",
    "        # set parametric prior on w\n",
    "        self.w_loc = pnn.PyroParam(torch.zeros((dim, )))\n",
    "        self.log_w_scale = pnn.PyroParam(torch.zeros((dim, )))\n",
    "        self.w = pnn.PyroSample(\n",
    "            lambda self: pdistr.Normal(self.w_loc, torch.exp(self.log_w_scale)).to_event(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor, y: torch.Tensor = None):\n",
    "        batch_size = X.shape[0]\n",
    "        if self.num_data_samples:\n",
    "            size = self.num_data_samples\n",
    "            subsample_size = batch_size\n",
    "        else:\n",
    "            size = batch_size\n",
    "            subsample_size = None\n",
    "\n",
    "        p = torch.sigmoid(X.matmul(self.w))\n",
    "        with pyro.plate(\"data_batch\", size=size, subsample_size=subsample_size):\n",
    "            pyro.sample(\"y\", pdistr.Bernoulli(p), obs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitSoloModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        elbo_f: pyro.infer.elbo.ELBOModule,\n",
    "        predictive: pyro.infer.Predictive,\n",
    "        num_data_samples: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_data_samples = num_data_samples\n",
    "        self.accuracy_computer = Accuracy('binary')\n",
    "\n",
    "        self.elbo_f = elbo_f\n",
    "        self.model: SoloModel = elbo_f.model\n",
    "        self.guide = elbo_f.guide\n",
    "\n",
    "        self.predictive = predictive\n",
    "\n",
    "    def training_step(self, batch: tuple[torch.Tensor], batch_idx: int):\n",
    "        X, y = batch\n",
    "\n",
    "        elbo_loss = self.elbo_f(X, y)\n",
    "\n",
    "        self.log(\"Train/ELBO\", elbo_loss, prog_bar=True)\n",
    "\n",
    "        return elbo_loss\n",
    "    \n",
    "    def validation_step(self, batch: tuple[torch.Tensor], batch_idx: int):\n",
    "        X, y = batch\n",
    "\n",
    "        y_pred = (self.predictive(X, y=None)[\"y\"].mean(dim=0) > 0.5).to(torch.float32)\n",
    "\n",
    "        self.accuracy_computer.update(y_pred, y)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"Test/Accuracy\", self.accuracy_computer.compute())\n",
    "        self.accuracy_computer.reset()  \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.elbo_f.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type           | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | accuracy_computer | BinaryAccuracy | 0      | train\n",
      "1 | elbo_f            | ELBOModule     | 8      | train\n",
      "2 | model             | SoloModel      | 4      | train\n",
      "3 | guide             | AutoNormal     | 4      | train\n",
      "4 | predictive        | Predictive     | 8      | train\n",
      "-------------------------------------------------------------\n",
      "8         Trainable params\n",
      "0         Non-trainable params\n",
      "8         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirill/.cache/pypoetry/virtualenvs/bmm-multitask-learning-_LQwnQjl-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirill/.cache/pypoetry/virtualenvs/bmm-multitask-learning-_LQwnQjl-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/kirill/.cache/pypoetry/virtualenvs/bmm-multitask-learning-_LQwnQjl-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:04<00:00,  1.59it/s, v_num=0, Train/ELBO=131.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:04<00:00,  1.59it/s, v_num=0, Train/ELBO=131.0]\n",
      "Training model 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type           | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | accuracy_computer | BinaryAccuracy | 0      | train\n",
      "1 | elbo_f            | ELBOModule     | 8      | train\n",
      "2 | model             | SoloModel      | 4      | train\n",
      "3 | guide             | AutoNormal     | 4      | train\n",
      "4 | predictive        | Predictive     | 8      | train\n",
      "-------------------------------------------------------------\n",
      "8         Trainable params\n",
      "0         Non-trainable params\n",
      "8         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:04<00:00,  1.65it/s, v_num=0, Train/ELBO=108.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:04<00:00,  1.65it/s, v_num=0, Train/ELBO=108.0]\n",
      "Training model 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type           | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | accuracy_computer | BinaryAccuracy | 0      | train\n",
      "1 | elbo_f            | ELBOModule     | 8      | train\n",
      "2 | model             | SoloModel      | 4      | train\n",
      "3 | guide             | AutoNormal     | 4      | train\n",
      "4 | predictive        | Predictive     | 8      | train\n",
      "-------------------------------------------------------------\n",
      "8         Trainable params\n",
      "0         Non-trainable params\n",
      "8         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:03<00:00,  1.91it/s, v_num=0, Train/ELBO=197.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:03<00:00,  1.91it/s, v_num=0, Train/ELBO=197.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_MODELS):\n",
    "    print(f\"Training model {i}\\n\")\n",
    "\n",
    "    model = SoloModel(config.dim, config.size)\n",
    "    guide = AutoNormal(model)\n",
    "\n",
    "    # num elbo particles is equivallent to variational multitask\n",
    "    num_elbo_particles = config.classifier_num_particles * config.latent_num_particles\n",
    "    elbo_f = Trace_ELBO(num_elbo_particles)(model, guide)\n",
    "\n",
    "    # All relevant parameters need to be initialized before ``configure_optimizer`` is called.\n",
    "    # Since we used AutoNormal guide our parameters have not be initialized yet.\n",
    "    # Therefore we initialize the model and guide by running one mini-batch through the loss.\n",
    "    mini_batch = next(iter(DataLoader(train_datasets[0], batch_size=1)))\n",
    "    elbo_f(*mini_batch)\n",
    "\n",
    "    # this choice of num_predictive_particles is rather balancing\n",
    "    num_predictive_particles = num_elbo_particles\n",
    "    predictive = pyro.infer.Predictive(model, guide=guide, num_samples=num_predictive_particles)\n",
    "\n",
    "    lit_model = LitSoloModel(elbo_f, predictive, config.size)\n",
    " \n",
    "    train_dataloader = DataLoader(train_datasets[i], batch_size=config.batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_datasets[i], batch_size=config.batch_size)\n",
    "\n",
    "    logger = CSVLogger(\"solo_logs\", f\"model_{i}\")\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"Train/ELBO\", min_delta=1e-3, patience=5, mode=\"min\")\n",
    "    ]\n",
    "\n",
    "    trainer = L.Trainer(logger=logger, callbacks=callbacks, **dict(config.trainer))\n",
    "    trainer.fit(lit_model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_log = [pd.read_csv(f\"solo_logs/model_{i}/version_0/metrics.csv\") for i in range(NUM_MODELS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Test/Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Train/ELBO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "af12bd50-8179-443d-850b-56d5cd144051",
       "rows": [
        [
         "0",
         "0.625",
         null,
         "0",
         "6"
        ],
        [
         "1",
         "0.75",
         null,
         "1",
         "13"
        ],
        [
         "2",
         "0.6000000238418579",
         null,
         "2",
         "20"
        ],
        [
         "3",
         "0.6000000238418579",
         null,
         "3",
         "27"
        ],
        [
         "4",
         "0.75",
         null,
         "4",
         "34"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test/Accuracy</th>\n",
       "      <th>Train/ELBO</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Test/Accuracy  Train/ELBO  epoch  step\n",
       "0          0.625         NaN      0     6\n",
       "1          0.750         NaN      1    13\n",
       "2          0.600         NaN      2    20\n",
       "3          0.600         NaN      3    27\n",
       "4          0.750         NaN      4    34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_log[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmm-multitask-learning-_LQwnQjl-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
